# 多模型支持更新说明

## 更新内容

系统支持多个 AI 模型提供商：**DeepSeek** 和 **Qwen**（统一使用 OpenAI 兼容 API）。

## 主要变更

### 1. 新增文件

- `services/aiProvider.js`: AI 模型提供者抽象层，统一处理不同模型的调用
- `AI_MODELS.md`: 多模型支持使用说明文档

### 2. 修改文件

- `api/analyze.js`: 更新为支持多模型选择
- `package.json`: 添加 `openai` 依赖（用于 DeepSeek 和 Qwen），移除 `@google/genai` 依赖
- `env.dev` / `env.prod`: 添加 AI 模型相关环境变量配置
- `docker-compose.dev.yml` / `docker-compose.prod.yml`: 添加 AI 模型环境变量传递

### 3. 技术实现

#### 后端架构

- **抽象层设计**: 通过 `services/aiProvider.js` 统一处理不同模型的调用
- **统一 API 格式**: 所有模型统一使用 OpenAI 兼容 API 格式，简化代码实现
- **自动兼容性处理**: 自动处理 JSON Schema 兼容性问题

#### 模型切换方式

1. **环境变量配置**（全局默认）:
   ```bash
   AI_PROVIDER=deepseek  # 或 qwen
   DEEPSEEK_API_KEY=your_key
   QWEN_API_KEY=your_key
   ```

2. **API 请求参数**（临时切换）:
   ```json
   {
     "type": "word",
     "text": "测试",
     "provider": "deepseek",
     "model": "deepseek-chat"
   }
   ```

## 配置步骤

### 1. 安装新依赖

```bash
npm install
```

### 2. 更新环境变量

编辑 `.env.dev` 或 `.env.prod` 文件，添加：

```bash
# AI 模型配置
AI_PROVIDER=deepseek  # 选择默认模型

# API Keys
DEEPSEEK_API_KEY=your_deepseek_api_key
QWEN_API_KEY=your_qwen_api_key  # 可选
```

### 3. 重启服务

如果使用 Docker：

```bash
./scripts/start.sh dev  # 或 prod
```

## 兼容性说明

- ✅ **前端无需修改**: 前端代码无需任何修改，继续使用 `geminiService.ts`
- ✅ **API 接口兼容**: `/api/analyze` 接口保持向后兼容，新增可选参数

## 支持的模型

| 提供商 | 默认模型 | API 端点 | 获取 API Key |
|--------|---------|---------|------------|
| DeepSeek | deepseek-chat | https://api.deepseek.com/v1 | https://platform.deepseek.com/ |
| Qwen | qwen-plus | https://dashscope.aliyuncs.com/compatible-mode/v1 | https://dashscope.console.aliyun.com/ |

## 注意事项

1. **API Key 安全**: 请妥善保管 API Key，不要提交到版本控制系统
2. **模型兼容性**: 不同模型对 JSON Schema 的支持可能不同，系统已自动处理兼容性问题
3. **费用**: 不同模型的计费方式可能不同，请参考各提供商的定价信息
4. **响应格式**: 所有模型都返回统一的 JSON 格式，确保前端兼容性

## 故障排查

### API Key 错误
- 检查环境变量中的 API Key 是否正确配置
- 确认 API Key 是否有效且未过期

### 模型不支持 JSON Schema
- 系统会自动回退到 JSON 模式
- 如果仍有问题，请检查模型名称是否正确

### 请求超时
- 检查网络连接
- 确认 API 端点可访问

## 详细文档

更多详细信息请参考 `AI_MODELS.md` 文件。
